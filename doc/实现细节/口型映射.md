# 文本驱动口型技术文档

## 1. 系统概述

文本驱动口型系统是一个基于Live2D模型的实时口型同步解决方案，通过分析文本内容生成对应的口型动画时间轴，实现虚拟角色的自然说话效果。

### 1.1 核心功能
- 文本到拼音转换
- 元音提取与分类
- 口型参数映射
- 实时动画驱动
- 平滑过渡处理

### 1.2 技术架构
```
前端 (Vue.js) ←→ 后端 (Flask) ←→ GPT-SoVITS (TTS)
     ↓              ↓
Live2D模型     文本处理引擎
```

## 2. 后端实现

### 2.1 核心文件
- `backend/streamTTSBackend/app.py` - 主要后端服务
- `backend/sovits 运行方法.txt` - GPT-SoVITS运行指南

### 2.2 主要API接口

#### 2.2.1 文本到口型时间轴接口
```python
@app.route('/text2mouth_timeline', methods=['POST'])
def text2mouth_timeline():
    """
    将文本转换为口型动画时间轴
    
    请求参数:
    - text: 要转换的文本
    - duration: 预期时长(秒)
    
    返回数据:
    - timeline: 时间轴数组，每个元素包含:
      - start: 开始时间(秒)
      - end: 结束时间(秒)
      - vowel: 元音类型
      - char: 对应字符
    """
```

#### 2.2.2 文本到口型参数接口
```python
@app.route('/text2mouth_param', methods=['POST'])
def text2mouth_param():
    """
    将文本转换为帧级别的口型参数
    
    请求参数:
    - text: 要转换的文本
    - duration: 预期时长(秒)
    - fps: 帧率(默认30)
    
    返回数据:
    - mouth_param: 每帧的嘴型开合度数组
    """
```

### 2.3 核心算法

#### 2.3.1 元音提取算法
```python
def extract_vowel(py):
    """
    从拼音中提取元音，支持复合元音
    
    算法逻辑:
    1. 优先检查复合元音 (ai, ao, ei, ou, an, en, ang, eng等)
    2. 再检查基本元音 (a, o, e, i, u, ü)
    3. 返回小写元音字符串
    """
```

#### 2.3.2 字符时长计算
```python
def get_char_duration(char, vowel):
    """
    根据字符和元音类型计算发音时长
    
    时长配置:
    - 基本元音: 0.15-0.3秒
    - 复合元音: 0.25-0.35秒
    - 标点符号: 0.1秒
    - 数字: 0.2秒
    - 轻声字: 0.15秒
    """
```

#### 2.3.3 时间轴生成流程
1. **文本预处理**: 将文本按字符分割
2. **拼音转换**: 使用pypinyin库获取每个字符的拼音
3. **元音提取**: 从拼音中提取元音类型
4. **时长计算**: 根据字符类型和元音计算发音时长
5. **时间轴构建**: 生成包含时间信息的口型数据
6. **时长调整**: 根据预期总时长进行缩放调整

## 3. 前端实现

### 3.1 核心文件
- `frontend/src/views/Live2DModel.vue` - 主要前端组件

### 3.2 主要功能模块

#### 3.2.1 字幕驱动口型同步
```javascript
const updateSubtitleSync = (timelineResult) => {
    // 1. 时间轴解析
    // 2. 当前时间定位
    // 3. 口型参数计算
    // 4. 平滑过渡处理
    // 5. 参数应用
    // 6. 递归调用
};
```

#### 3.2.2 口型参数配置
```javascript
const vowelConfigs = {
    // 基本元音配置
    'a': {
        openY: 0.8,      // 嘴巴开合度
        width: 0.7,      // 嘴巴宽度
        form: 0.8,       // 嘴型形状
        smile: 0.1,      // 微笑程度
        frown: 0         // 撇嘴程度
    },
    // 复合元音配置
    'ai': {
        openY: 0.75,
        width: 0.65,
        form: 0.7,
        smile: 0.2,
        frown: 0
    }
    // ... 更多配置
};
```

#### 3.2.3 动态效果处理
- **震动效果**: 添加轻微的正弦震动
- **随机微调**: 每500ms添加极小幅度的随机变化
- **平滑过渡**: 在字符切换时进行插值过渡
- **参数限制**: 确保所有参数在合理范围内

### 3.3 Live2D参数映射

#### 3.3.1 核心参数
- `ParamMouthOpenY`: 嘴巴开合度 (0-1)
- `ParamMouthOpenWidth`: 嘴巴宽度 (0-1)
- `ParamMouthForm`: 嘴型形状 (0-1)
- `ParamMouthSmile`: 微笑程度 (0-0.3)
- `ParamMouthFrown`: 撇嘴程度 (0-0.3)

#### 3.3.2 参数应用
```javascript
// 应用所有嘴型参数
try {
    model.internalModel.coreModel.setParameterValueById("ParamMouthOpenY", finalConfig.openY);
    model.internalModel.coreModel.setParameterValueById("ParamMouthOpenWidth", finalConfig.width);
    model.internalModel.coreModel.setParameterValueById("ParamMouthForm", finalConfig.form);
    model.internalModel.coreModel.setParameterValueById("ParamMouthSmile", finalConfig.smile);
    model.internalModel.coreModel.setParameterValueById("ParamMouthFrown", finalConfig.frown);
} catch (e) {
    // 降级处理：只设置基本参数
    model.internalModel.coreModel.setParameterValueById("ParamMouthOpenY", finalConfig.openY);
}
```

## 4. 数据流程

### 4.1 完整处理流程
```
文本输入 → 拼音转换 → 元音提取 → 时长计算 → 时间轴生成 → 前端接收 → 参数映射 → Live2D渲染
```

### 4.2 数据格式

#### 4.2.1 时间轴数据格式
```json
{
    "timeline": [
        {
            "start": 0.0,
            "end": 0.25,
            "vowel": "a",
            "char": "你"
        },
        {
            "start": 0.25,
            "end": 0.5,
            "vowel": "h",
            "char": "好"
        }
    ]
}
```

#### 4.2.2 口型参数格式
```json
{
    "mouth_param": [0.8, 0.7, 0.6, 0.5, ...]  // 每帧的嘴型开合度
}
```

## 5. 性能优化

### 5.1 前端优化
- **防重复处理**: 避免相同字幕在100ms内重复处理
- **动画帧优化**: 使用requestAnimationFrame确保流畅动画
- **参数缓存**: 缓存当前参数值，减少重复计算
- **降级处理**: 对不支持的参数进行优雅降级

### 5.2 后端优化
- **拼音缓存**: 缓存常用字符的拼音结果
- **批量处理**: 支持批量文本处理
- **错误处理**: 完善的异常处理机制

## 6. 配置说明

### 6.1 元音配置
系统支持以下元音类型：
- **基本元音**: a, o, e, i, u, ü
- **复合元音**: ai, ao, ei, ou, ia, ie, ua, uo
- **鼻音**: an, en, in, un, ang, eng, ing, ong

### 6.2 时长配置
- **基础时长**: 0.2秒/字符
- **元音时长**: 根据元音类型调整 (0.15-0.35秒)
- **特殊字符**: 标点符号、数字、轻声字有特殊时长

### 6.3 参数范围
- **开合度**: 0.2-1.0 (最小轻微张开)
- **宽度**: 0.1-1.0
- **形状**: 0.0-1.0
- **表情**: 0.0-0.3

## 7. 部署说明

### 7.1 环境要求
- Python 3.9+
- Node.js 16+
- Vue.js 3.x
- Live2D Cubism SDK

### 7.2 启动步骤
1. 启动后端服务: `python backend/streamTTSBackend/app.py`
2. 启动前端服务: `npm run dev`
3. 确保GPT-SoVITS服务运行在9880端口

### 7.3 端口配置
- 前端: 5173 (默认)
- 后端: 5001
- GPT-SoVITS: 9880

## 8. 故障排除

### 8.1 常见问题
1. **口型不同步**: 检查时间轴数据是否正确
2. **参数异常**: 检查Live2D模型是否支持相应参数
3. **性能问题**: 检查动画帧率和参数更新频率

### 8.2 调试方法
- 开启浏览器控制台查看详细日志
- 检查网络请求是否正常
- 验证时间轴数据的完整性

## 9. 扩展功能

### 9.1 可扩展方向
- 支持更多语言
- 添加情感表达
- 优化音素识别
- 支持自定义口型配置

### 9.2 接口扩展
- 支持批量文本处理
- 添加实时流式处理
- 支持自定义时长算法

## 10. 总结

文本驱动口型系统通过精确的文本分析和参数映射，实现了高质量的Live2D口型同步效果。系统具有良好的扩展性和稳定性，为虚拟角色提供了自然的说话表现能力。